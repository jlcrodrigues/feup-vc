{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z0fcOsburr8"
      },
      "source": [
        "# Introduction\n",
        "This notebook showcases the implementation and some results regarding Task 3. This task was splitted into to two subtasks: 3.1 for the object detection and 3.2 for the object segmentation.\n",
        "\n",
        "The implementation and results of each training for subtask are explained in detail in the report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7fV7pLNx01B"
      },
      "source": [
        "# Task 3.1 - Object Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qktC4DJjvgb5"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8JCPYFDujk1"
      },
      "source": [
        "Installation of the necessary libraries and mouting of google drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5sZOcXq2vcrh",
        "outputId": "b016c45d-794f-4a16-90f0-53e0cdfa33f3"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3hv6Hm_voYg",
        "outputId": "49389b08-477b-4642-d6dd-b9a4aefcee6e"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from google.colab import drive\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKLKe8kgtLry"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_pHkB0lv7Yc"
      },
      "source": [
        "### Initial training\n",
        "\n",
        "* 20 epochs\n",
        "\n",
        "* images containing just 1 lego piece from the provided dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvfgRh2twCxy"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"yolov8s.pt\") # default pre-trained model\n",
        "\n",
        "results = model.train(data=\"/content/gdrive/MyDrive/Colab_Notebooks/VCOM/1_piece/data.yaml\", epochs=20, imgsz=640)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zv7Ao_j1x_Uo"
      },
      "source": [
        "### Results\n",
        "![title](training1/confusion_matrix.png)\n",
        "![title](training1/F1_curve.png)\n",
        "![title](training1/PR_curve.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHVn1H6ArCJ0"
      },
      "source": [
        "### Second Training\n",
        "* 100 epochs\n",
        "\n",
        "* images containing number of legos from 1 to 15 from the provided dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1yund7hlvr8W",
        "outputId": "196e5d90-16b7-46f6-e6e5-954d72df6d15"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"yolov8s.pt\") # default pre-trained model\n",
        "\n",
        "results = model.train(data=\"/content/gdrive/MyDrive/Colab_Notebooks/VCOM/data.yaml\", epochs=100, imgsz=640)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2hji3fAyDj9"
      },
      "source": [
        "### Results\n",
        "![title](training2/confusion_matrix2.png)\n",
        "![title](training2/F1_curve2.png)\n",
        "![title](training2/loss.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTpKUqnfJen3"
      },
      "source": [
        "### Third Training\n",
        "\n",
        "* 200 epochs\n",
        "\n",
        "* images containing number of legos from 1 to 15 from the provided dataset\n",
        "\n",
        "* hyperparmeter \"patience\" set to 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "collapsed": true,
        "id": "zglb80_0v5hj",
        "outputId": "b79012a0-9f8d-4725-caaf-37a0cdcd3299"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"yolov8s.pt\") # default pre-trained model\n",
        "\n",
        "results = model.train(data=\"/content/gdrive/MyDrive/Colab_Notebooks/VCOM/data.yaml\", epochs=200, patience=10 ,imgsz=640)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF1YfU9wyJdz"
      },
      "source": [
        "### Results\n",
        "![title](training3/confusion_matrix.png)\n",
        "![title](training3/F1_curve.png)\n",
        "![title](training3/PR_curve.png)\n",
        "![title](training3/results.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRSLXXTgsXGb"
      },
      "source": [
        "## Test model with test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on0lkwWiseLg",
        "outputId": "7d51f520-9781-4dfb-c91b-dfc25eac842b"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"/content/gdrive/MyDrive/Colab_Notebooks/VCOM/runs/detect/train/train2/weights/best.pt\")\n",
        "results = model.val(data=\"/content/gdrive/MyDrive/Colab_Notebooks/VCOM/data2.yaml\")\n",
        "# copy results to drive\n",
        "!cp -r /content/runs/detect/val /content/gdrive/MyDrive/Colab_Notebooks/VCOM/runs/detect/test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCkRi7d5wbpH"
      },
      "source": [
        "## Simple Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i99pwgkrwc_k"
      },
      "outputs": [],
      "source": [
        "# Load a model\n",
        "import cv2\n",
        "model = YOLO(\"/content/gdrive/MyDrive/Colab_Notebooks/VCOM/runs/detect/train/train2/weights/best.pt\")\n",
        "\n",
        "# Predict with the model\n",
        "results = model(source=\"/content/gdrive/MyDrive/Colab_Notebooks/test3pieces.jpg\")  # predict on an image\n",
        "\n",
        "# Display result\n",
        "annotated_image = results[0].plot()\n",
        "cv2.imwrite(\"test3pieces_annotated.jpg\", annotated_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdPf2AJVk8pZ"
      },
      "source": [
        "# Task 3.2 - Object Segmentation\n",
        "\n",
        "Just like task 3.1, the implementation and and thought process behind this task is explained in detail in the report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FEa9lEEkv5V"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "model = YOLO(\"/content/gdrive/MyDrive/Colab_Notebooks/VCOM/runs/detect/train/train2/weights/best.pt\")\n",
        "\n",
        "base_dir = \"/content/gdrive/MyDrive/Colab_Notebooks/VCOM/test/images\"\n",
        "\n",
        "for subdir in os.listdir(base_dir):\n",
        "    subdir_path = os.path.join(base_dir, subdir)\n",
        "    if os.path.isdir(subdir_path):\n",
        "        for file in os.listdir(subdir_path):\n",
        "            file_path = os.path.join(subdir_path, file)\n",
        "\n",
        "            if file.endswith(\".jpg\"):\n",
        "                results = model(file_path, show=False)\n",
        "\n",
        "                image = cv2.imread(file_path)\n",
        "\n",
        "                if image is None:\n",
        "                    print(f\"Could not open or find the image: {file_path}\")\n",
        "                    continue\n",
        "\n",
        "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                # Improve the contrast of the image\n",
        "                image_lab = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2LAB)\n",
        "                l, a, b = cv2.split(image_lab)\n",
        "                l = cv2.equalizeHist(l)\n",
        "                image_lab = cv2.merge((l, a, b))\n",
        "                image_rgb = cv2.cvtColor(image_lab, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "                # Improve the contrast of the image\n",
        "                #image_hsv = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HSV)\n",
        "                #h, s, v = cv2.split(image_hsv)\n",
        "                #v = cv2.equalizeHist(v)\n",
        "                #image_hsv = cv2.merge((h, s, v))\n",
        "                #image_rgb = cv2.cvtColor(image_hsv, cv2.COLOR_HSV2RGB)\n",
        "\n",
        "                # Improve the contrast of the image\n",
        "                #clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "                #l = clahe.apply(l)\n",
        "                #image_lab = cv2.merge((l, a, b))\n",
        "                #image_rgb = cv2.cvtColor(image_lab, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "                for box in results[0].boxes.xyxy:\n",
        "\n",
        "                    x1, y1, x2, y2 = map(int, box.tolist())\n",
        "\n",
        "                    cropped_image = image_rgb[y1:y2, x1:x2]\n",
        "\n",
        "                    # Apply Gaussian blur\n",
        "                    cropped_image = cv2.GaussianBlur(cropped_image, (5, 5), 0)\n",
        "\n",
        "                    # Convert the cropped image to HSV to better seperate the colors\n",
        "                    #cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "                    gray_cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "                    # Apply global binary threshold with Otsu's method\n",
        "                    #_, binary_cropped_image = cv2.threshold(gray_cropped_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "                    # Apply adaptive thresholding\n",
        "                    #binary_cropped_image = cv2.adaptiveThreshold(gray_cropped_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "\n",
        "                    # Apply global binary threshold\n",
        "                    _, binary_cropped_image = cv2.threshold(gray_cropped_image, 0, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "                    # Apply GrabCut segmentation\n",
        "                    mask = np.zeros(cropped_image.shape[:2], np.uint8)\n",
        "                    bgd_model = np.zeros((1, 65), np.float64)\n",
        "                    fgd_model = np.zeros((1, 65), np.float64)\n",
        "                    rect = (1, 1, cropped_image.shape[1] - 2, cropped_image.shape[0] - 2)\n",
        "                    cv2.grabCut(cropped_image, mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)\n",
        "                    mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
        "                    segmented_cropped_image = cropped_image * mask2[:, :, np.newaxis]\n",
        "\n",
        "                    # Apply k-means clustering\n",
        "                    pixel_values = segmented_cropped_image.reshape((-1, 3))\n",
        "                    pixel_values = np.float32(pixel_values)\n",
        "                    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 0.2)\n",
        "                    k = 5\n",
        "                    _, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "                    centers = np.uint8(centers)\n",
        "                    segmented_image = centers[labels.flatten()]\n",
        "                    segmented_image = segmented_image.reshape(segmented_cropped_image.shape)\n",
        "\n",
        "                    # Apply morphological operations\n",
        "                    kernel = np.ones((3,3), np.uint8)\n",
        "                    segmented_image = cv2.morphologyEx(segmented_image, cv2.MORPH_OPEN, kernel)\n",
        "                    segmented_image = cv2.morphologyEx(segmented_image, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "                    image_rgb[y1:y2, x1:x2] = segmented_image\n",
        "\n",
        "                segmented_image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "                original_image_resized = cv2.resize(cv2.imread(file_path), (800, 800))\n",
        "                segmented_image_resized = cv2.resize(segmented_image_bgr, (800, 800))\n",
        "\n",
        "                cv2.imshow(\"Original Image\", original_image_resized)\n",
        "                cv2.imshow(\"Segmented Image\", segmented_image_resized)\n",
        "\n",
        "                cv2.waitKey(0)\n",
        "                cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
