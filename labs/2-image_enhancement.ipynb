{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Image Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os, numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Path to directory with images\n",
    "dataDir = 'Images_03a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Show image\u001b[39;00m\n\u001b[1;32m      5\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m, img)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyWindow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Open noisy image\n",
    "img = cv2.imread(os.path.join(dataDir, 'coins_03_noisy.jpg'))\n",
    "\n",
    "# Show image\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Filtering and Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Check tutorial here!](https://docs.opencv.org/4.x/dc/dd3/tutorial_gausian_median_blur_bilateral_filter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mean filter to the image\n",
    "img_mean_filter = cv2.blur(img, (4,4))\n",
    "\n",
    "# Show image\n",
    "cv2.imshow('image', img_mean_filter)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a Gaussian filter to the image\n",
    "img_gaussian_filter = cv2.GaussianBlur(img, (5,5), 0)\n",
    "\n",
    "# Show image\n",
    "cv2.imshow('image', img_gaussian_filter)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.1: Apply median and bilateral filters to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/jose.l.rodrigues/.local/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img = cv2.imread(os.path.join(dataDir, 'coins_03_noisy.jpg'))\n",
    "# Apply a median filter to the image\n",
    "img_median_filter = cv2.medianBlur(img, 5)\n",
    "\n",
    "# Show image\n",
    "cv2.imshow('image', img_median_filter)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('image')\n",
    "\n",
    "# Apply a bilateral filter to the image\n",
    "img_bilateral_filter = cv2.bilateralFilter(img, 9, 75, 75)\n",
    "\n",
    "# Show image\n",
    "cv2.imshow('image', img_bilateral_filter)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('image')\n",
    "\n",
    "# Save images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.2: Add salt and pepper noise to a grayscale image and check the result of previous filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/jose.l.rodrigues/.local/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os, numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Path to directory with images\n",
    "dataDir = './Images_03a'\n",
    "img = cv2.imread(os.path.join(dataDir, 'coins_02.jpg'))\n",
    "\n",
    "grayscale_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "h, w = grayscale_image.shape\n",
    "num_pixels = h * w\n",
    "\n",
    "num_pixels_to_change = int(0.05 * num_pixels)\n",
    "\n",
    "pixels_to_alter = np.random.randint(num_pixels, size=num_pixels_to_change)\n",
    "\n",
    "x = pixels_to_alter % w\n",
    "y = pixels_to_alter % h \n",
    "\n",
    "color = np.random.choice([0, 1], num_pixels_to_change)\n",
    "\n",
    "for i in range(num_pixels_to_change):\n",
    "    grayscale_image[y[i]][x[i]] = color[i]*255\n",
    "\n",
    "cv2.imshow('image', grayscale_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.3: Reproduce gaussian blur with custom convolution (using [ndimage.convolve()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/jose.l.rodrigues/.local/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "import cv2\n",
    "import os, numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Path to directory with images\n",
    "dataDir = './Images_03a'\n",
    "img = cv2.imread(os.path.join(dataDir, 'coins_02.jpg'))\n",
    "\n",
    "# Convert image to grayscale\n",
    "grayscale_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# normalize image\n",
    "grayscale_image = grayscale_image / 255\n",
    "\n",
    "# define gaussian kernel\n",
    "kernel = np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]])\n",
    "\n",
    "# normalize kernel\n",
    "kernel = kernel / np.sum(kernel)\n",
    "\n",
    "# apply convolution\n",
    "convolution_result = ndimage.convolve(grayscale_image, kernel)\n",
    "\n",
    "# apply gaussian blur\n",
    "img_gaussian_blur = cv2.GaussianBlur(grayscale_image, (3,3), 0)\n",
    "\n",
    "# show results\n",
    "cv2.imshow('gaussian blut', img_gaussian_blur)\n",
    "cv2.imshow('convolution', convolution_result)\n",
    "cv2.imshow('original', grayscale_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.4: Define custom convolution (using [ndimage.convolve()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.5: Add salt and pepper noise to a colored image and apply the previous filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1.6: Apply custom filter to colored image with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load low contrast image\n",
    "img = cv2.imread(os.path.join(dataDir, 'face_lowContrast_01.jpg'), 0) # Change this, according to your image's path\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Histograms Equalization](https://docs.opencv.org/master/d6/dc7/group__imgproc__hist.html#ga7e54091f0c937d49bf84152a16f76d6e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing contrast with Histograms Equalization\n",
    "img_with_he = cv2.equalizeHist(img)\n",
    "\n",
    "cv2.imshow('histogram_equalization', img_with_he)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contrast Limited Adaptive Histogram Equalization](https://docs.opencv.org/master/d6/dc7/group__imgproc__hist.html#gad689d2607b7b3889453804f414ab1018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing contrast with CLAHE\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "img_with_CLAHE = clahe.apply(img)\n",
    "\n",
    "cv2.imshow('clahe', img_with_CLAHE)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.1: Apply Histogram Equalization to a colored image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.2: Apply CLAHE to a colored image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
